---
title: "Home repair tax credit program"
author: "Bingchu Chen, Anna Duan"
date: "10/25/2020"
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
---

```{r setup, message=FALSE, warning=FALSE, include=TRUE, results='hide'}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
```

```{r load_packages, message=FALSE, warning=FALSE, include=TRUE, results='hide'}
options(scipen=10000000)

library(tidyverse)
library(kableExtra)
library(caret)
library(knitr) 
library(pscl)
library(plotROC)
library(pROC)
library(lubridate)
library(viridis)
library(gridExtra)
library(forcats)
```

```{r load_data, message=FALSE, warning=FALSE, include=TRUE, results='hide'}
palette5 <- c("#d24ae8","#f0b660","#981FAC","#f5614e","#00bafe")
palette4 <- c("#d24ae8","#f0b660","#981FAC","#f5614e")
palette2 <- c("#d24ae8","#f0b660")

root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")

#housingsubsidy <- read.csv("E:/Upenn/CPLN508/tax_credits/Home-Repair-Tax-Credit-Program/housingSubsidy.csv") %>%
housingsubsidy <- read.csv("/Users/annaduan/Documents/GitHub/Home-Repair-Tax-Credit-Program/housingSubsidy.csv") %>% 
  rename(tookSubsidyNum = y_numeric,
         prevMktgOutcome = poutcome,
         tookSubsidy = y)
  
```

## Motivation
1. One paragraph on the motivation for the analysis.
```{r uptake rate figure, message=FALSE, warning=FALSE, results='hide'}

ggplot(mutate(housingsubsidy, tookSubsidy = fct_infreq(tookSubsidy))) + geom_bar(aes(x = tookSubsidy)) +
  labs(title = "Figure XX: Results of Prior Campaigns", x = "Repair Credit Uptake Among Contacted Homeowners", y = "Count of Homeowners") +
  plotTheme()
```


## Data visualizations
2. Develop and interpret data visualizations that describe feature importance/correlation.

```{r Data visualizations, fig.height=10, fig.width=10, message=FALSE, warning=FALSE, results='hide'}
#Continuous variables
housingsubsidy %>%
  dplyr::select(tookSubsidy, age, campaign, pdays, previous, spent_on_repairs, unemploy_rate, cons.price.idx, cons.conf.idx, inflation_rate) %>% 
  gather(Variable, value, -tookSubsidy) %>%
    ggplot(aes(tookSubsidy, value, fill=tookSubsidy)) + 
      geom_bar(position = "dodge", stat = "summary", fun = "mean") + 
      facet_wrap(~Variable, scales = "free") +
      scale_color_viridis(option = "D")+
      labs(x="Accepted Subsidy", y="Mean", 
           title = "Feature Associations with Likelihood of Accepting Subsidy",
           subtitle = "(continous outcomes)") +
      theme(legend.position = "none")


#yes/no variables
housingsubsidy %>%
  dplyr::select(tookSubsidy, mortgage, taxbill_in_phl) %>%
  gather(Variable, value, -tookSubsidy) %>%
  count(Variable, value, tookSubsidy) %>%
  filter(value == "yes") %>%
    ggplot(aes(tookSubsidy, n, fill = tookSubsidy)) +   
      geom_bar(position = "dodge", stat="identity") +
      facet_wrap(~Variable, scales = "free", ncol=2) +
      scale_fill_viridis(discrete = "TRUE", option = "B") +
      labs(x="Accepted Subsidy", y="Count",
           title = "Feature associations with the likelihood of accepting subsidy",
           subtitle = "Two category features (Yes and No)") +
      plotTheme() + theme(legend.position = "none")

#more than 2 categories
housingsubsidy %>%
  dplyr::select(tookSubsidy, job, marital, education, contact, month, day_of_week, prevMktgOutcome, ) %>%
  gather(Variable, value, -tookSubsidy) %>%
  count(Variable, value, tookSubsidy) %>%
  ggplot(aes(value, n, fill = tookSubsidy)) +   
    geom_bar(position = "dodge", stat="identity") +
    facet_wrap(~Variable, scales="free", ncol=2) +
    scale_fill_manual(values = palette2) +
    labs(x="Accepted Subsidy", y="Count",
         title = "Feature associations with the likelihood of accepting subsidy",
         subtitle = "Multiple category features") +
    plotTheme() + theme(axis.text.x = element_text(angle = 45, hjust = 1))



##for continuous variables
housingsubsidy %>%
    dplyr::select(tookSubsidy, age, spent_on_repairs ,unemploy_rate , campaign, inflation_rate, previous, cons.price.idx, cons.conf.idx) %>%
    gather(Variable, value, -tookSubsidy) %>%
    ggplot() + 
    geom_density(aes(value, color=tookSubsidy), fill = "transparent") + 
    facet_wrap(~Variable, scales = "free") +
    scale_fill_manual(values = palette2) +
    labs(title = "Feature distributions subsidy vs. no subsidy",
         subtitle = "(continous outcomes)", x = "Value", y = "Density") +
    theme(legend.position = "none") +
  plotTheme()


```


## Data wrangling

## Add new features
4. Engineer new features that significantly increase the Sensitivity.

a.Interpret your new features in one paragraph.

b.Show a regression summary for both the kitchen sink and your engineered regression. 

c.Cross validate both models; compare and interpret two facetted plots of ROC, Sensitivity and Specificity.

```{r Add new features, message=FALSE, warning=FALSE, include=TRUE, results='hide'}

housingsubsidy <- 
  housingsubsidy %>% 
  mutate(employStatus = case_when(job == "unemployed"  ~ "unemployed",
                                   job == "retired" ~ "retired",
                                  job == "student" ~ "student",
                                   TRUE  ~ "employed"),
         ageGroup = case_when(age >= 18 & age < 35 ~ "Young adult",
                                   age >= 35 & age < 65  ~ "Middle-aged adult",
                                   age >= 65  ~ "Old adult"), 
         degreeGroup = case_when(education == "high.school" ~ "high school",
                                   education == "university.degree" ~ "bachelor's",
                                   education == "unknown" ~ "unknown",
                                  education == "illiterate" ~ "illiterate",
                                  TRUE ~ "Below high school"),
         industry = case_when(job == "blue-collar" | job == "technician" ~ "blue collar",
                              job == "services" | job == "housemaid" ~ "services",
                              job == "entrepreneur" | job == "self-employed" ~ "entrepreneur",
                              job == "admin." | job == "management" ~ "white collar",
                              TRUE ~ "Unknown"),
         lastContact = case_when(pdays == 999 ~ "never contacted",
                                 pdays < 7 ~ "Past week",
                                 pdays >= 7 & pdays < 14 ~ "1-2 Weeks",
                                 pdays >= 14 & pdays < 21 ~ "2-3 Weeks",
                               TRUE ~ "More than 3 Weeks"),
         contactedBefore = case_when(previous == 0 ~ "no",
                                  TRUE ~ "yes"))
```


3. Split your data into a 65/35 training/test set.

```{r Split data, message=FALSE, warning=FALSE, include=TRUE, results='hide'}
set.seed(10)
trainIndex <- createDataPartition(housingsubsidy$tookSubsidy, 
                                  y = paste(housingsubsidy$taxLien, housingsubsidy$degreeGroup, housingsubsidy$lastContact),
                                  p = .65,
                                  list = FALSE,
                                  times = 1)
housingsubsidyTrain <- housingsubsidy[ trainIndex,]
housingsubsidyTest  <- housingsubsidy[-trainIndex,]
```


4b: Show a regression summary for both the kitchen sink and your engineered regression.
```{r regression, message=FALSE, warning=FALSE, include=TRUE}
#include all to see the coefficients
reg0 <- glm(tookSubsidyNum ~ .,
                  data=housingsubsidyTrain %>% 
                    dplyr::select(-X, -tookSubsidy), #delete all the NAs
                  family="binomial" (link="logit"))

summary(reg0)
pR2(reg0)

#without engineered features
reg1 <- glm(tookSubsidyNum ~ .,
                  data=housingsubsidyTrain %>% 
                    dplyr::select(-employStatus, -ageGroup, -degreeGroup, -industry, -lastContact, -contactedBefore, -X, -tookSubsidy),
                  family="binomial" (link="logit"))

summary(reg1)
pR2(reg1)

#with engineered features
reg2 <- glm(tookSubsidyNum ~ .,
                  data=housingsubsidyTrain %>% 
                    dplyr::select(-age, -job, -education, -pdays, -previous, -X, -tookSubsidy, -taxLien),
                  family="binomial" (link="logit"))

summary(reg2)
pR2(reg2)

#BC: we need to exclude X and tookSubsidy here to avoid overfitting
#AD: I see! THat's smart, I didn't think of that

#with variables that explain the most based on reg1 and reg2
reg3 <- glm(tookSubsidyNum ~ .,
                  data=housingsubsidyTrain %>% 
                    dplyr::select(-X, -tookSubsidy, -industry, -degreeGroup, -employStatus,-contactedBefore, -taxLien),
                  family="binomial" (link="logit"))

summary(reg3)
pR2(reg3)


```


```{r goodness of fit, message=FALSE, warning=FALSE, results='hide'}


testProbs <- data.frame(Outcome = as.factor(housingsubsidyTest$tookSubsidyNum),
                        Probs = predict(reg3, housingsubsidyTest, type= "response"))


ggplot(testProbs, aes(x = Probs, fill = as.factor(Outcome))) +     #AD: This doesn't look right.. #BC: it's looking normal now but our sensitivity is so low
  geom_density() +
  facet_grid(Outcome ~ .) +
  scale_fill_manual(values = palette2) +
  labs(x = "Accepted Subsidy", y = "Density of probabilities",
       title = "Distribution of predicted probabilities by observed outcome") +
  plotTheme() + theme(strip.text.x = element_text(size = 18),
        legend.position = "none")


testProbs <- 
  testProbs %>%
  mutate(predOutcome  = as.factor(ifelse(testProbs$Probs > 0.5 , 1, 0))) #change from 0.5 to raise sensitivity 



#confusion matrix
caret::confusionMatrix(testProbs$predOutcome, testProbs$Outcome, 
                       positive = "1")

```

## Interpret the ROC curve
5. Output an ROC curve for your new model and interpret it.
```{r ROC curve , message=FALSE, warning=FALSE, results='hide'}
ggplot(testProbs, aes(d = as.numeric(Outcome), m = Probs)) +
  geom_roc(n.cuts = 50, labels = FALSE, colour = "#FE9900") +  #BC: not sure if we need to change 50 here too
  style_roc(theme = theme_grey) +
  geom_abline(slope = 1, intercept = 0, size = 1.5, color = 'grey') +
  labs(title = "ROC Curve - reg3")

#area under curve 
pROC::auc(testProbs$Outcome, testProbs$Probs) 
#0.7538
#we choose point false positive 0.91?
```

```{r cross validation, message=FALSE, warning=FALSE, results='hide'}
#4c: Cross validate both models; compare and interpret two facetted plots of ROC, Sensitivity and Specificity.

ctrl <- trainControl(method = "cv", number = 100, classProbs=TRUE, summaryFunction=twoClassSummary)

#kitchen sink
cvFit0 <- train(tookSubsidy ~ ., data = housingsubsidy %>% 
                                   dplyr::select(-X, -tookSubsidyNum), 
                method="glm", family="binomial",
                metric="ROC", trControl = ctrl)

cvFit0

#selected features
cvFit3 <- train(tookSubsidy ~ ., data = housingsubsidy %>% 
                                   dplyr::select(-X, -tookSubsidyNum, -industry, -degreeGroup, -employStatus,-contactedBefore, -taxLien), 
                method="glm", family="binomial",
                metric="ROC", trControl = ctrl)

cvFit3

#kitchen sink
dplyr::select(cvFit0$resample, -Resample) %>%
  gather(metric, value) %>%
  left_join(gather(cvFit0$results[2:4], metric, mean)) %>%
  ggplot(aes(value)) + 
    geom_histogram(bins=35, fill = "#FF006A") +
    facet_wrap(~metric) +
    geom_vline(aes(xintercept = mean), colour = "#981FAC", linetype = 3, size = 1.5) +
    scale_x_continuous(limits = c(0, 1)) +
    labs(x="Kitchen Sink Model Goodness of Fit", y="Count", title="CV Goodness of Fit Metrics",
         subtitle = "Across-fold mean reprented as dotted lines") +
    plotTheme()

#selected model
dplyr::select(cvFit3$resample, -Resample) %>%
  gather(metric, value) %>%
  left_join(gather(cvFit3$results[2:4], metric, mean)) %>%
  ggplot(aes(value)) + 
    geom_histogram(bins=35, fill = "#FF006A") +
    facet_wrap(~metric) +
    geom_vline(aes(xintercept = mean), colour = "#981FAC", linetype = 3, size = 1.5) +
    scale_x_continuous(limits = c(0, 1)) +
    labs(x="Selected Model Goodness of Fit", y="Count", title="CV Goodness of Fit Metrics",
         subtitle = "Across-fold mean reprented as dotted lines") +
    plotTheme()

```

## Cost benefit analysis
6a.Write out the cost/benefit equation for each confusion metric.
6b Create the 'Cost/Benefit Table' as seen above.

If we predict that a household will take the credit, then HCD is willing to allocate $2,850 per homeowner which includes staff and resources to facilitate mailers, phone calls, and information/counseling sessions at the HCD offices. Given the new targeting algorithm, we should now assume 25% of contacted eligible homeowners take the credit. The remainder receive the marketing allocation but do not take the credit.

The credit costs $5,000 per homeowner which can be used toward home improvement. Academic researchers in Philadelphia evaluated the program finding that houses that transacted after taking the credit, sold with a $10,000 premium, on average. Homes surrounding the repaired home see an aggregate premium of $56,000, on average. 

1. 10000 premium per house that accepts subsidy
2. 2850 in marketing for each house
3. 5000 subsidy per house that accepts
4. 25% of contacted homeowners take subsidy


```{r Cost/Benefit Table, message=FALSE, warning=FALSE, include=TRUE}
cost_benefit_table <-
   testProbs %>%
      count(predOutcome, Outcome) %>%
      summarize(True_Negative = sum(n[predOutcome==0 & Outcome==0]),
                True_Positive = sum(n[predOutcome==1 & Outcome==1]),
                False_Negative = sum(n[predOutcome==0 & Outcome==1]),
                False_Positive = sum(n[predOutcome==1 & Outcome==0])) %>%
       gather(Variable, Count) %>%
       mutate(Revenue =
               case_when(Variable == "True_Negative"  ~ 0,  
                         Variable == "True_Positive"  ~ ((10000 - 7850) * (Count * .25)) + (-2850 * (Count * .75)),   #AD: according to canvas, we can't count the 56000 neighbor premium because we don't know how many neighbors - to only count one neighbor per house is inaccurate
                         Variable == "False_Negative" ~ 0 * Count,
                         Variable == "False_Positive" ~ (-2850)*Count)) %>%
    bind_cols(data.frame(Description = c(
              "Predicted correctly homeowner would not take the credit, no marketing resources were allocated, and no credit was allocated.",
              "Predicted correctly homeowner would take the credit; allocated the marketing resources, and 25% took the credit.",
              "We predicted that a homeowner would not take the credit but they did. These are likely homeowners who signed up for reasons unrelated to the marketing campaign. Thus, we '0 out' this category, assuming the cost/benefit of this is $0.",
              "Predicted incorrectly homeowner would take the credit; allocated marketing resources; no credit allocated.")))

kable(cost_benefit_table) %>% 
  kable_styling(font_size = 12, full_width = F,    #AD: also seems wrong
                bootstrap_options = c("striped", "hover", "condensed")) %>%
  footnote(general_title = "\n",
           general = "Table XX")
```

6c Plot the confusion metric outcomes for each Threshold.

```{r Plot the confusion metric, message=FALSE, warning=FALSE, results='hide'}
iterateThresholds <- function(data) {
  x = .01
  all_prediction <- data.frame()
  while (x <= 1) {
  
  this_prediction <-
      testProbs %>%
      mutate(predOutcome = ifelse(Probs > x, 1, 0)) %>%
      count(predOutcome, Outcome) %>%
      summarize(True_Negative = sum(n[predOutcome==0 & Outcome==0]),
                True_Positive = sum(n[predOutcome==1 & Outcome==1]),
                False_Negative = sum(n[predOutcome==0 & Outcome==1]),
                False_Positive = sum(n[predOutcome==1 & Outcome==0])) %>%
     gather(Variable, Count) %>%
     mutate(Revenue =
               ifelse(Variable == "True_Negative", Count * 0,
               ifelse(Variable == "True_Positive",((10000 - 7850) * (Count * .25)) + (-2850 * (Count * .75)),
               ifelse(Variable == "False_Negative", 0 * Count,
               ifelse(Variable == "False_Positive", (-2850) * Count, 0)))), #AD: because didn't send marketing material
            Threshold = x)
  
  all_prediction <- rbind(all_prediction, this_prediction)
  x <- x + .01
  }
return(all_prediction)
}

whichThreshold <- iterateThresholds(testProbs2)

whichThreshold_revenue <- 
whichThreshold %>% 
    group_by(Threshold) %>% 
    summarize(Revenue = sum(Revenue))

#plot
whichThreshold %>%
  ggplot(.,aes(Threshold, Revenue, colour = Variable)) +
  geom_point() +
  scale_colour_manual(values = palette5[c(5, 1:3)]) +    
  labs(title = "Profit by confusion matrix type and threshold",
       y = "Profit") +
  plotTheme() +
  guides(colour=guide_legend(title = "Confusion Matrix")) 

whichThreshold_revenue <- 
  whichThreshold %>% 
    mutate(actualcreditno = ifelse(Variable == "True_Positive", (Count * .75), ifelse(Variable == "False_Positive", Count, 0)),
           actualcredityes = ifelse(Variable == "True_Positive", (Count * .25), ifelse(Variable == "False_Negative", Count, 0))) %>%  
    group_by(Threshold) %>% 
    summarize(Revenue = sum(Revenue),
              sumcredityes = sum(actualcredityes))
             # Actual_creditno_Rate = sum(actualcreditno) / sum(Count),
             # Total_credit_counts = sum(Count) - sum(actualcreditno),
             # Actual_creditno_Revenue_Loss =  sum(actualcreditno * 10000),
             # Revenue_Next_Period = Revenue - Actual_creditno_Revenue_Loss) 


whichThreshold_revenue[1:5,]


maxrevenueTest <- whichThreshold_revenue[,1:2] #something is going wrong 
                                                  #AD: looks slightly more accurate now...
```

6d Create two small multiple plots that show Threshold as a function of Total_Revenue and Total_Count_of_Credits. Interpret this.

```{r two small multiple plots, message=FALSE, warning=FALSE, results='hide'}

#AD: what is Total_Count_of_Credits? Is it the number of subsidies that we give out?
p1<-
  ggplot(whichThreshold_revenue)+
  geom_line(aes(x = Threshold, y = Revenue))+
  geom_vline(xintercept =  pull(arrange(whichThreshold_revenue, -Revenue)[1,1]))+
    labs(title = "Model Total_Revenue By Threshold For Test Sample",
         subtitle = "Vertical Line Denotes Optimal Threshold")
  
  #total_count_of_credits plot

p2<-  ggplot(whichThreshold_revenue)+
  geom_line(aes(x = Threshold, y = sumcredityes))+
  geom_vline(xintercept =  pull(arrange(whichThreshold_revenue, -sumcredityes)[1,1]))+
    labs(title = "Model Total_Count_of_Credits By Threshold For Test Sample",
         subtitle = "Vertical Line Denotes Optimal Threshold")

 grid.arrange(p1, p2, ncol =1, top = "Threshold as a function of Total_Revenue and Total_Count_of_Credits")
```

6e Create a table of the Total_Revenue and Total_Count_of_Credits allocated for 2 categories. 50%_Threshold and your Optimal_Threshold.

```{r Create a table, message=FALSE, warning=FALSE, include=TRUE}
#0.91
threshold_table <- whichThreshold_revenue[c(16, 50), c("Threshold", "Revenue", "sumcredityes")]
threshold_table %>%
  group_by(Threshold) %>%
  kable(caption = "Total_Revenue and Total_Count_of_Credits", col.names = c("Threshold", "Total revenue", "Total count of credits")) %>%
    kable_styling("striped", full_width = T) 

```

## Conclusions
7. Conclude whether and why this model should or shouldn't be put into production. What could make the model better? What would you do to ensure that the marketing materials resulted in a better response rate?
