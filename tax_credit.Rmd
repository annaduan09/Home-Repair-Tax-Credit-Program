---
title: "Home repair tax credit program"
author: "Bingchu Chen, Anna Duan"
date: "10/25/2020"
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
```

```{r load_packages, warning = FALSE}
options(scipen=10000000)

library(tidyverse)
library(kableExtra)
library(caret)
library(knitr) 
library(pscl)
library(plotROC)
library(pROC)
library(lubridate)
library(viridis)
library(gridExtra)
```

```{r load_data, cache = TRUE}
palette5 <- c("#d24ae8","#f0b660","#981FAC","#f5614e","#00bafe")
palette4 <- c("#d24ae8","#f0b660","#981FAC","#f5614e")
palette2 <- c("#d24ae8","#f0b660")

root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")

housingsubsidy <- read.csv("E:/Upenn/CPLN508/tax_credits/Home-Repair-Tax-Credit-Program/housingSubsidy.csv") %>%
#housingsubsidy <- read.csv("/Users/annaduan/Documents/GitHub/Home-Repair-Tax-Credit-Program/housingSubsidy.csv") %>% 
  rename(tookSubsidyNum = y_numeric,
         prevMktgOutcome = poutcome,
         tookSubsidy = y)
  
```

## Motivation
1. One paragraph on the motivation for the analysis.

## Data visualizations
2. Develop and interpret data visualizations that describe feature importance/correlation.

```{r Data visualizations, message = FALSE, warning = FALSE}
#Continuous variables
housingsubsidy %>%
  dplyr::select(tookSubsidy, age, campaign, pdays, previous, spent_on_repairs, unemploy_rate, cons.price.idx, cons.conf.idx, inflation_rate) %>% 
  gather(Variable, value, -tookSubsidy) %>%
    ggplot(aes(tookSubsidy, value, fill=tookSubsidy)) + 
      geom_bar(position = "dodge", stat = "summary", fun = "mean") + 
      facet_wrap(~Variable, scales = "free") +
      scale_color_viridis(option = "D")+
      labs(x="Accepted Subsidy", y="Mean", 
           title = "Feature Associations with Likelihood of Accepting Subsidy",
           subtitle = "(continous outcomes)") +
      theme(legend.position = "none")


#yes/no variables
housingsubsidy %>%
  dplyr::select(tookSubsidy, mortgage, taxbill_in_phl) %>%
  gather(Variable, value, -tookSubsidy) %>%
  count(Variable, value, tookSubsidy) %>%
  filter(value == "yes") %>%
    ggplot(aes(tookSubsidy, n, fill = tookSubsidy)) +   
      geom_bar(position = "dodge", stat="identity") +
      facet_wrap(~Variable, scales = "free", ncol=2) +
      scale_fill_viridis(discrete = "TRUE", option = "B") +
      labs(x="Accepted Subsidy", y="Count",
           title = "Feature associations with the likelihood of accepting subsidy",
           subtitle = "Two category features (Yes and No)") +
      plotTheme() + theme(legend.position = "none")

#more than 2 categories
housingsubsidy %>%
  dplyr::select(tookSubsidy, job, marital, education, contact, month, day_of_week, prevMktgOutcome, ) %>%
  gather(Variable, value, -tookSubsidy) %>%
  count(Variable, value, tookSubsidy) %>%
  ggplot(aes(value, n, fill = tookSubsidy)) +   
    geom_bar(position = "dodge", stat="identity") +
    facet_wrap(~Variable, scales="free", ncol=2) +
    scale_fill_manual(values = palette2) +
    labs(x="Accepted Subsidy", y="Count",
         title = "Feature associations with the likelihood of accepting subsidy",
         subtitle = "Multiple category features") +
    plotTheme() + theme(axis.text.x = element_text(angle = 45, hjust = 1))



##for continuous variables
housingsubsidy %>%
    dplyr::select(tookSubsidy, age, spent_on_repairs ,unemploy_rate , campaign, inflation_rate, previous, cons.price.idx, cons.conf.idx) %>%
    gather(Variable, value, -tookSubsidy) %>%
    ggplot() + 
    geom_density(aes(value, color=tookSubsidy), fill = "transparent") + 
    facet_wrap(~Variable, scales = "free") +
    scale_fill_manual(values = palette2) +
    labs(title = "Feature distributions subsidy vs. no subsidy",
         subtitle = "(continous outcomes)", x = "Value", y = "Density") +
    theme(legend.position = "none") +
  plotTheme()


```


## Data wrangling

## Add new features
4. Engineer new features that significantly increase the Sensitivity.

a.Interpret your new features in one paragraph.

b.Show a regression summary for both the kitchen sink and your engineered regression. 

c.Cross validate both models; compare and interpret two facetted plots of ROC, Sensitivity and Specificity.

```{r Add new features}

housingsubsidy <- 
  housingsubsidy %>% 
  mutate(employStatus = case_when(job == "unemployed"  ~ "unemployed",
                                   job == "retired" ~ "retired",
                                  job == "student" ~ "student",
                                   TRUE  ~ "employed"),
         ageGroup = case_when(age >= 18 & age < 35 ~ "Young adult",
                                   age >= 35 & age < 65  ~ "Middle-aged adult",
                                   age >= 65  ~ "Old adult"), 
         degreeGroup = case_when(education == "high.school" ~ "high school",
                                   education == "university.degree" ~ "bachelor's",
                                   education == "unknown" ~ "unknown",
                                  education == "illiterate" ~ "illiterate",
                                  TRUE ~ "Below high school"),
         industry = case_when(job == "blue-collar" | job == "technician" ~ "blue collar",
                              job == "services" | job == "housemaid" ~ "services",
                              job == "entrepreneur" | job == "self-employed" ~ "entrepreneur",
                              job == "admin." | job == "management" ~ "white collar",
                              TRUE ~ "Unknown"),
         lastContact = case_when(pdays == 999 ~ "never contacted",
                                 pdays < 7 ~ "Past week",
                                 pdays >= 7 & pdays < 14 ~ "1-2 Weeks",
                                 pdays >= 14 & pdays < 21 ~ "2-3 Weeks",
                               TRUE ~ "More than 3 Weeks"),
         contactedBefore = case_when(previous == 0 ~ "no",
                                  TRUE ~ "yes"))
```


3. Split your data into a 65/35 training/test set.

```{r Data wrangling}
set.seed(10)
trainIndex <- createDataPartition(housingsubsidy$tookSubsidy, 
                                  y = paste(housingsubsidy$taxLien, housingsubsidy$degreeGroup, housingsubsidy$lastContact),
                                  p = .65,
                                  list = FALSE,
                                  times = 1)
housingsubsidyTrain <- housingsubsidy[ trainIndex,]
housingsubsidyTest  <- housingsubsidy[-trainIndex,]
```


4b: Show a regression summary for both the kitchen sink and your engineered regression.
```{r regression}
#include all to see the coefficients
reg0 <- glm(tookSubsidyNum ~ .,
                  data=housingsubsidyTrain %>% 
                    dplyr::select(-X, -tookSubsidy), #delete all the NAs
                  family="binomial" (link="logit"))

summary(reg0)
pR2(reg0)

#without engineered features, namely the kitchen sink 
reg1 <- glm(tookSubsidyNum ~ .,
                  data=housingsubsidyTrain %>% 
                    dplyr::select(-employStatus, -ageGroup, -degreeGroup, -industry, -lastContact, -contactedBefore, -X, -tookSubsidy),
                  family="binomial" (link="logit"))

summary(reg1)
pR2(reg1)

#with engineered features
reg2 <- glm(tookSubsidyNum ~ .,
                  data=housingsubsidyTrain %>% 
                    dplyr::select(-age, -job, -education, -pdays, -previous, -X, -tookSubsidy, -taxLien),
                  family="binomial" (link="logit"))

summary(reg2)
pR2(reg2)

#BC: we need to exclude X and tookSubsidy here to avoid overfitting
#AD: I see! THat's smart, I didn't think of that

#with variables that explain the most based on reg1 and reg2
reg3 <- glm(tookSubsidyNum ~ .,
                  data=housingsubsidyTrain %>% 
                    dplyr::select(-X, -tookSubsidy, -industry, -degreeGroup, -employStatus,-contactedBefore, -taxLien),
                  family="binomial" (link="logit"))

summary(reg3)
pR2(reg3)


```


```{r goodness of fit}

#ks
testProbs_ks <- data.frame(Outcome = as.factor(housingsubsidyTest$tookSubsidyNum),
                        Probs = predict(reg1, housingsubsidyTest, type= "response"))



  ggplot(testProbs_ks, aes(x = Probs, fill = as.factor(Outcome))) + 
  geom_density() +
  facet_grid(Outcome ~ .) +
  scale_fill_manual(values = palette2) +
  labs(x = "Accepted Subsidy", y = "Density of probabilities",
       title = "Distribution of predicted probabilities by observed outcome") +
  plotTheme() + theme(strip.text.x = element_text(size = 18),
        legend.position = "none")


testProbs_ks <- 
  testProbs_ks %>%
  mutate(predOutcome  = as.factor(ifelse(testProbs_ks$Probs > 0.5 , 1, 0))) 

#confusion matrix
caret::confusionMatrix(testProbs_ks$predOutcome, testProbs_ks$Outcome, 
                       positive = "1")

#reg2 engineering features
testProbs_r2 <- data.frame(Outcome = as.factor(housingsubsidyTest$tookSubsidyNum),
                        Probs = predict(reg2, housingsubsidyTest, type= "response"))


ggplot(testProbs_r2, aes(x = Probs, fill = as.factor(Outcome))) + 
  geom_density() +
  facet_grid(Outcome ~ .) +
  scale_fill_manual(values = palette2) +
  labs(x = "Accepted Subsidy", y = "Density of probabilities",
       title = "Distribution of predicted probabilities by observed outcome") +
  plotTheme() + theme(strip.text.x = element_text(size = 18),
        legend.position = "none")


testProbs_r2 <- 
  testProbs_r2 %>%
  mutate(predOutcome  = as.factor(ifelse(testProbs_r2$Probs > 0.5 , 1, 0))) 

#confusion matrix
caret::confusionMatrix(testProbs_r2$predOutcome, testProbs_r2$Outcome, 
                       positive = "1")

```

## Interpret the ROC curve
5. Output an ROC curve for your new model and interpret it.


```{r cross validation}
#4c: Cross validate both models; compare and interpret two facetted plots of ROC, Sensitivity and Specificity.

ctrl <- trainControl(method = "cv", number = 100, classProbs=TRUE, summaryFunction=twoClassSummary)

#kitchen sink
cvFit1 <- train(tookSubsidy ~ ., data = housingsubsidy %>% 
                                   dplyr::select(-employStatus, -ageGroup, -degreeGroup, -industry, -lastContact, -contactedBefore, -X, -tookSubsidyNum), 
                method="glm", family="binomial",
                metric="ROC", trControl = ctrl)

cvFit1

#selected features
cvFit2 <- train(tookSubsidy ~ ., data = housingsubsidy %>% 
                                   dplyr::select(-age, -job, -education, -pdays, -previous, -X, -taxLien, -tookSubsidyNum), 
                method="glm", family="binomial",
                metric="ROC", trControl = ctrl)

cvFit2

#kitchen sink
f1<-
dplyr::select(cvFit1$resample, -Resample) %>%
  gather(metric, value) %>%
  left_join(gather(cvFit1$results[2:4], metric, mean)) %>%
  ggplot(aes(value)) + 
    geom_histogram(bins=35, fill = "#FF006A") +
    facet_wrap(~metric) +
    geom_vline(aes(xintercept = mean), colour = "#981FAC", linetype = 3, size = 1.5) +
    scale_x_continuous(limits = c(0, 1)) +
    labs(x="Kitchen Sink Model Goodness of Fit", y="Count", title="CV Goodness of Fit Metrics",
         subtitle = "Across-fold mean reprented as dotted lines kitchen sink") +
    plotTheme()

#selected model
f2<-
dplyr::select(cvFit2$resample, -Resample) %>%
  gather(metric, value) %>%
  left_join(gather(cvFit3$results[2:4], metric, mean)) %>%
  ggplot(aes(value)) + 
    geom_histogram(bins=35, fill = "#FF006A") +
    facet_wrap(~metric) +
    geom_vline(aes(xintercept = mean), colour = "#981FAC", linetype = 3, size = 1.5) +
    scale_x_continuous(limits = c(0, 1)) +
    labs(x="Selected Model Goodness of Fit", y="Count", title="CV Goodness of Fit Metrics",
         subtitle = "Across-fold mean reprented as dotted lines new features model") +
    plotTheme()


grid.arrange(f1, f2, ncol =1, top = "ROC, Sensivity and specificity of two models")
```

```{r ROC curve , echo=FALSE}

#r2

ggplot(testProbs_r2, aes(d = as.numeric(Outcome), m = Probs)) +
  geom_roc(n.cuts = 50, labels = FALSE, colour = "#FE9900") + 
  style_roc(theme = theme_grey) +
  geom_abline(slope = 1, intercept = 0, size = 1.5, color = 'grey') +
  labs(title = "ROC Curve - features model")

#area under curve 
pROC::auc(testProbs_r2$Outcome, testProbs_r2$Probs) 


```

## Cost benefit analysis
6a.Write out the cost/benefit equation for each confusion metric.
6b Create the 'Cost/Benefit Table' as seen above.

If we predict that a household will take the credit, then HCD is willing to allocate $2,850 per homeowner which includes staff and resources to facilitate mailers, phone calls, and information/counseling sessions at the HCD offices. Given the new targeting algorithm, we should now assume 25% of contacted eligible homeowners take the credit. The remainder receive the marketing allocation but do not take the credit.

The credit costs $5,000 per homeowner which can be used toward home improvement. Academic researchers in Philadelphia evaluated the program finding that houses that transacted after taking the credit, sold with a $10,000 premium, on average. Homes surrounding the repaired home see an aggregate premium of $56,000, on average. 

1. 10000 premium per house that accepts subsidy
2. 2850 in marketing for each house
3. 5000 subsidy per house that accepts
4. 25% of contacted homeowners take subsidy


```{r Cost/Benefit Table}
cost_benefit_table <-
   testProbs %>%
      count(predOutcome, Outcome) %>%
      summarize(True_Negative = sum(n[predOutcome==0 & Outcome==0]),
                True_Positive = sum(n[predOutcome==1 & Outcome==1]),
                False_Negative = sum(n[predOutcome==0 & Outcome==1]),
                False_Positive = sum(n[predOutcome==1 & Outcome==0])) %>%
       gather(Variable, Count) %>%
       mutate(Revenue =
               case_when(Variable == "True_Negative"  ~ 0,  
                         Variable == "True_Positive"  ~ ((10000 - 7850) * (Count * .25)) + (-2850 * (Count * .75)),   #AD: according to canvas, we can't count the 56000 neighbor premium because we don't know how many neighbors - to only count one neighbor per house is inaccurate
                         Variable == "False_Negative" ~ 0 * Count,
                         Variable == "False_Positive" ~ (-2850)*Count)) %>%
    bind_cols(data.frame(Description = c(
              "Predicted correctly homeowner would not take the credit, no marketing resources were allocated, and no credit was allocated.",
              "Predicted correctly homeowner would take the credit; allocated the marketing resources, and 25% took the credit.",
              "We predicted that a homeowner would not take the credit but they did. These are likely homeowners who signed up for reasons unrelated to the marketing campaign. Thus, we '0 out' this category, assuming the cost/benefit of this is $0.",
              "Predicted incorrectly homeowner would take the credit; allocated marketing resources; no credit allocated.")))

kable(cost_benefit_table) %>% 
  kable_styling(font_size = 12, full_width = F,    #AD: also seems wrong
                bootstrap_options = c("striped", "hover", "condensed")) %>%
  footnote(general_title = "\n",
           general = "Table XX")
```

6c Plot the confusion metric outcomes for each Threshold.

```{r Plot the confusion metric}
iterateThresholds <- function(data) {
  x = .01
  all_prediction <- data.frame()
  while (x <= 1) {
  
  this_prediction <-
      testProbs %>%
      mutate(predOutcome = ifelse(Probs > x, 1, 0)) %>%
      count(predOutcome, Outcome) %>%
      summarize(True_Negative = sum(n[predOutcome==0 & Outcome==0]),
                True_Positive = sum(n[predOutcome==1 & Outcome==1]),
                False_Negative = sum(n[predOutcome==0 & Outcome==1]),
                False_Positive = sum(n[predOutcome==1 & Outcome==0])) %>%
     gather(Variable, Count) %>%
     mutate(Revenue =
               ifelse(Variable == "True_Negative", Count * 0,
               ifelse(Variable == "True_Positive",((10000 - 7850) * (Count * .25)) + (-2850 * (Count * .75)),
               ifelse(Variable == "False_Negative", 0 * Count,
               ifelse(Variable == "False_Positive", (-2850) * Count, 0)))), #AD: because didn't send marketing material
            Threshold = x)
  
  all_prediction <- rbind(all_prediction, this_prediction)
  x <- x + .01
  }
return(all_prediction)
}

whichThreshold <- iterateThresholds(testProbs2)

whichThreshold_revenue <- 
whichThreshold %>% 
    group_by(Threshold) %>% 
    summarize(Revenue = sum(Revenue))

#plot
whichThreshold %>%
  ggplot(.,aes(Threshold, Revenue, colour = Variable)) +
  geom_point() +
  scale_colour_manual(values = palette5[c(5, 1:3)]) +    
  labs(title = "Profit by confusion matrix type and threshold",
       y = "Profit") +
  plotTheme() +
  guides(colour=guide_legend(title = "Confusion Matrix")) 

whichThreshold_revenue <- 
  whichThreshold %>% 
    mutate(actualcreditno = ifelse(Variable == "True_Positive", (Count * .75), ifelse(Variable == "False_Positive", Count, 0)),
           actualcredityes = ifelse(Variable == "True_Positive", (Count * .25), ifelse(Variable == "False_Negative", Count, 0))) %>%  
    group_by(Threshold) %>% 
    summarize(Revenue = sum(Revenue),
              sumcredityes = sum(actualcredityes))

whichThreshold_revenue[1:5,]


maxrevenueTest <- whichThreshold_revenue[,1:2] #something is going wrong 
                                                  #AD: looks slightly more accurate now...
```

6d Create two small multiple plots that show Threshold as a function of Total_Revenue and Total_Count_of_Credits. Interpret this.

```{r two small multiple plots}

p1<-
  ggplot(whichThreshold_revenue)+
  geom_line(aes(x = Threshold, y = Revenue))+
  geom_vline(xintercept =  pull(arrange(whichThreshold_revenue, -Revenue)[1,1]))+
    labs(title = "Model Total_Revenue By Threshold For Test Sample",
         subtitle = "Vertical Line Denotes Optimal Threshold")

p2<-  ggplot(whichThreshold_revenue)+
  geom_line(aes(x = Threshold, y = sumcredityes))+
  geom_vline(xintercept =  pull(arrange(whichThreshold_revenue, -sumcredityes)[1,1]))+
    labs(title = "Model Total_Count_of_Credits By Threshold For Test Sample",
         subtitle = "Vertical Line Denotes Optimal Threshold")

 grid.arrange(p1, p2, ncol =1, top = "Threshold as a function of Total_Revenue and Total_Count_of_Credits")
```

6e Create a table of the Total_Revenue and Total_Count_of_Credits allocated for 2 categories. 50%_Threshold and your Optimal_Threshold.

```{r Create a table}
#0.91
threshold_table <- whichThreshold_revenue[c(16, 50), c("Threshold", "Revenue", "sumcredityes")]
threshold_table %>%
  group_by(Threshold) %>%
  kable(caption = "Total_Revenue and Total_Count_of_Credits", col.names = c("Threshold", "Total revenue", "Total count of credits")) %>%
    kable_styling("striped", full_width = T) 

```

## Conclusions
7. Conclude whether and why this model should or shouldn't be put into production. What could make the model better? What would you do to ensure that the marketing materials resulted in a better response rate?
